Certainly! Here are condensed notes on the prompting techniques mentioned:

1. **Zero-shot Prompting**:
   - Generates responses without specific examples in the prompt.
   - Relies on pre-existing knowledge to infer context.

2. **Few-shot Prompting**:
   - Uses a small number of examples to generalize responses.
   - Helps the model adapt to similar tasks with limited training data.

3. **Chain-of-Thought Prompting**:
   - Prompts consist of interconnected questions/statements.
   - Requires coherence and relevance throughout the sequence.

4. **Self-Consistency**:
   - Evaluates responses for internal coherence.
   - Encourages consistency within the prompt.

5. **Generate Knowledge Prompting**:
   - Tasks the model with synthesizing new information.
   - Requires insights beyond the given prompt.

6. **Prompt Chaining**:
   - Connects multiple prompts sequentially.
   - Builds continuity and coherence in the conversation.

7. **Tree of Thoughts**:
   - Organizes prompts in a hierarchical structure.
   - Represents different conversation directions.

8. **Retrieval Augmented Generation**:
   - Combines generative and retrieval-based methods.
   - Enhances contextuality and accuracy.

9. **Automatic Reasoning and Tool-use**:
   - Simulates logical reasoning or tool utilization.
   - Facilitates problem-solving in responses.

10. **Automatic Prompt Engineer**:
    - Automatically generates effective prompts.
    - Optimizes prompt design for tasks.

11. **Active-Prompt**:
    - Dynamically adjusts prompts based on responses.
    - Allows interactive refinement of prompts.

12. **Directional Stimulus Prompting**:
    - Provides specific cues to guide model behavior.
    - Shapes conversation context.

13. **Program-Aided Language Models**:
    - Incorporates programming elements in prompts.
    - Enables fine-grained control over generation.

14. **ReAct** (Response-Action Prompting):
    - Provides response-action pairs to guide behavior.
    - Facilitates structured interactions.

15. **Reflexion**:
    - Prompts the model to reflect on its outputs.
    - Encourages self-analysis and improvement.

16. **Multimodal CoT**:
    - Integrates multiple modalities in prompting.
    - Enables contextually rich interactions.

17. **Graph Prompting**:
    - Structures prompts and responses as a graph.
    - Defines relationships between elements.