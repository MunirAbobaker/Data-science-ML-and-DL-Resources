 #### Collection of free Notes,Courses,Videos,Projects,Articles and Repos Links To learn Machine learning ,Deep  learning,Python,SQL,CNN,NLP,GAN,GNN,Transfomers,Flask,Django,and End to End Machine learning Projects




# Python
![1_m0H6-tUbW6grMlezlb52yw](https://user-images.githubusercontent.com/110838853/226801494-9b9886b8-cd0d-4fc0-897a-d083a12b08f2.png)


### Python-Roadmap 
https://github.com/ashishpatel26/Python-Roadmap
https://github.com/hemansnation/Python-Roadmap

### Python Code Tutorials For all 
https://github.com/ashishpatel26/pythoncode-tutorials ### here We can Find python code for different kind of Projects for CNN,NLP,web Programming and ML


# Data analyst Roadmap
#### Data analyst Roadmap with Resources and Cheatsheets
https://github.com/mtahiraslan/data-analyst-roadmap


# Webscraping With python
https://github.com/ptyadana/Web-Scraping-and-API-in-Python ##Web Scraping and API in Python using beautifulsoup, requests, requests-xml, etc for processing multiple APIs and scraping multple sites such as youtube, soundcloud and many more.

#  Data science and Machine learning

![Data_Science_vs _Machine_Learning](https://user-images.githubusercontent.com/110838853/226796558-4cc9a0ba-c4aa-496d-9dba-60e70e671b5d.png)

#### Data science Roadmap for ML,DL,NLP,python,CNN,MLops
https://github.com/hemansnation/God-Level-Data-Science-ML-Full-Stack  ##
Everything you need to know for data science.
https://github.com/hemansnation/Data-Science-ML-Alpha-2022

#### List of Data Science and Machine Learning Resource
https://github.com/nishitpatel01/Data-Science-and-Machine-Learning-Resources ##List of Data Science and Machine Learning Resource for ML,Statistics,DL,Probalbility,NLP,Data Visualisation,Algorithms

#### Data Science and Machine Learning Projects
https://github.com/ptyadana/Data-Science-and-Machine-Learning-Projects-Dojo
##Collections of Data Science & ML projects and dojo where I practice Data Science, Machine Learning, Deep Learning and Data Visualization related skills, theories, probability, statistics, etc.

#### Data Science Projects
https://github.com/AnshuTrivedi/Data-Scientist-In-Python


# Artificial Intelligence 
![Artificial-Intellegence-e1634237254116-1024x371](https://user-images.githubusercontent.com/110838853/226801755-facaabc8-1bd4-4c83-a3de-bc99b23be4ea.jpeg)


Artificial intelligence (AI) is a broad field of computer science and engineering that focuses on developing intelligent machines that can perform tasks that typically require human intelligence, such as perception, reasoning, learning, and problem-solving.

AI systems are designed to learn from and adapt to their environment, enabling them to improve their performance over time. These systems can be classified into several categories based on their level of intelligence:

Reactive machines: These AI systems can only react to specific input data without having any memory or ability to learn from previous experiences. Examples of reactive machines include Deep Blue, a chess-playing computer program, and Siri, an intelligent personal assistant.

Limited memory machines: These AI systems can store and recall previous experiences, allowing them to make more informed decisions. Examples of limited memory machines include self-driving cars and personal robots.

Theory of mind machines: These AI systems have the ability to understand and predict the behavior of others by modeling their beliefs, desires, and intentions. Theory of mind machines are still largely theoretical, but they are an active area of research in AI.

Self-aware machines: These AI systems have a sense of self and consciousness, allowing them to understand their own state and emotions. Self-aware machines are still purely theoretical and may never be possible to create.

AI has many practical applications, including natural language processing, image and speech recognition, predictive analytics, and robotics. It is a rapidly advancing field, with new techniques and applications being developed every day.


<div align="center">
  <img src="https://user-images.githubusercontent.com/110838853/226782113-03fc1525-fb6d-47ce-9cda-4c534f12a27b.jpg" alt="AUG-2022_AI-Learning-fig1">
</div>

#### Artificial Intelligence for Beginners - A Curriculum 
https://github.com/ashishpatel26/AI-For-Beginners

#### Artificial Intelligence Resources 
https://github.com/ahmedbahaaeldin/From-0-to-Research-Scientist-resources-guide  ##Detailed and tailored guide for undergraduate students or anybody want to dig deep into the field of AI with solid foundation.



# Mathematics for ML
![97735WhatsApp Image 2021-05-31 at 8 41 44 PM](https://user-images.githubusercontent.com/110838853/226798432-bab7f034-3ebd-4654-a45c-60e77d512cbc.jpeg)

#### A collection of resources to learn mathematics for machine learning
https://github.com/dair-ai/Mathematics-for-ML

# Machine learning

![ml-e1610553826718](https://user-images.githubusercontent.com/110838853/226786032-2162bb7b-0903-4ed1-b468-97c257bc51ce.jpg)

Machine learning (ML) is a subfield of artificial intelligence (AI) that involves training algorithms to automatically learn patterns from data, without being explicitly programmed.

In machine learning, algorithms are designed to learn from data, identify patterns, and make predictions or decisions based on that data. The algorithms are trained using a variety of techniques such as supervised, unsupervised, and reinforcement learning.

Supervised learning involves training an algorithm on labeled data, where the input and output pairs are known. The algorithm learns to map inputs to outputs, allowing it to make predictions on new, unseen data. Examples of supervised learning include image classification, sentiment analysis, and spam detection.

Unsupervised learning involves training an algorithm on unlabeled data, where the algorithm must discover patterns or structure within the data. Clustering, anomaly detection, and dimensionality reduction are examples of unsupervised learning.

Reinforcement learning involves training an agent to make decisions in an environment by rewarding or punishing it based on its actions. The agent learns to maximize its reward over time, allowing it to make better decisions in the future.

Machine learning has many practical applications, including natural language processing, image and speech recognition, predictive analytics, and recommendation systems. It has become an essential tool for many businesses and organizations seeking to make data-driven decisions and automate complex tasks



#### Andrew NG Notes on ML
https://github.com/ashishpatel26/Andrew-NG-Notes

#### ML Course Notes and Videos
https://github.com/ashishpatel26/ML-Course-Notes


#### ML,DL,NLP Youtube Courses 
https://github.com/dair-ai/ML-YouTube-Courses


### Stanford Course(Standford CS231n 2017 Summary)
https://github.com/mbadry1/CS231n-2017-Summary

#### Data-Science-Tutorial-By-Lambda-School
https://github.com/ashishpatel26/Data-Science-Tutorial-By-Lambda-School

#### Explanation to key concepts in ML
https://github.com/dair-ai/ML-Papers-Explained

### ML Notebooks 
https://github.com/dair-ai/Mathematics-for-ML

#### Machine Learning Interview Preparation
https://www.geeksforgeeks.org/machine-learning/


# Deep learning

![ezgif-3-091b9a24fd](https://user-images.githubusercontent.com/110838853/226787169-b81940d2-399b-4038-ae19-9bf3ad530bbe.jpg)

Deep learning is a subfield of machine learning that is based on artificial neural networks with many layers. These networks are designed to learn complex representations of data through the use of multiple layers of interconnected nodes, each of which performs a simple computation.

In deep learning, the algorithm learns to extract features from raw data, such as images, sounds, and text, without the need for human feature engineering. This is achieved by stacking multiple layers of non-linear processing units, also known as neurons, to form a neural network that can automatically learn the features and relationships between them.

Deep learning models have shown impressive results in a variety of applications, including image and speech recognition, natural language processing, and game playing. For example, convolutional neural networks (CNNs) have been used to achieve state-of-the-art results in image classification, while recurrent neural networks (RNNs) have been used for speech recognition and natural language processing.

One of the key advantages of deep learning is its ability to learn from large amounts of data, making it particularly effective in applications where large datasets are available. Additionally, deep learning models can automatically learn to extract features from raw data, eliminating the need for manual feature engineering, which can be a time-consuming and error-prone process.

Overall, deep learning has become an essential tool in many areas of research and industry, enabling breakthroughs in fields such as computer vision, natural language processing, and robotics.


### Deeplearning.ai Course 

https://github.com/mbadry1/DeepLearning.ai-Summary

https://github.com/mbadry1/DeepLearning.ai-Summary/tree/master/1-%20Neural%20Networks%20and%20Deep%20Learning


https://github.com/Avik-Jain/DeepLearning.ai-Summary/tree/master/1-%20Neural%20Networks%20and%20Deep%20Learning

#### Andrew NG Notes on ML
https://github.com/ashishpatel26/Andrew-NG-Notes

#### ML,DL,NLP Youtube Courses 
https://github.com/dair-ai/ML-YouTube-Courses


#### Deep learning Course Notes and Videos
https://github.com/ashishpatel26/ML-Course-Notes

### Practical Deep learning for Coders from fast.ai-
https://course.fast.ai/Lessons/lesson1.html


### Full Stack Deep learning
https://fall2019.fullstackdeeplearning.com/course-content/setting-up-machine-learning-projects/metrics


### Deep learning Book
https://github.com/janishar/mit-deep-learning-book-pdf

### Deep Learning Notebooks 
https://github.com/dair-ai/Mathematics-for-ML




###  Trending-Deep-Learning
https://github.com/mbadry1/Trending-Deep-Learning
https://github.com/mbadry1/Top-Deep-Learning ##  Top Deep learning Repositories

### Data science process
https://resources.experfy.com/bigdata-cloud/the-data-science-process/

### How to build a regression-model
https://resources.experfy.com/bigdata-cloud/how-to-build-a-regression-model-in-python/

### How to build a model
https://resources.experfy.com/ai-ml/how-to-build-a-machine-learning-model/

https://copyassignment.com/8-steps-to-build-a-machine-learning-model/



# Neural network

![1_3fA77_mLNiJTSgZFhYnU0Q](https://user-images.githubusercontent.com/110838853/226782532-c79583a7-fe4e-4af8-92be-6c19dc261db4.png)

One min to have a general idea about Neural Network, which is a technique that could achieve many different aims, facial recognition, predicting, music composition, etc.

NN contains virtual ‘neurons’ that are arranged in layers that are connected to each other. The neurons pass on the information and thereby perform calculations.

The connections between the neurons also have values associated with them, called weights.

Those weights tell us how much the information from one layer matters for the next layer. The values of neurons and the weights of the connections are essentially the free parameters of the network.

By training the network, we want to find those values of the parameters that minimize a certain function, called the ‘loss function’. It is an optimization problem, we use a method called backpropagation to solve it.

Backpropagation means if the NN gives us a result that is not good enough, we go back and change the weights of neurons and their connections. This is how the network can learn from failure.
![1645940317303](https://user-images.githubusercontent.com/110838853/224456961-62efe7a4-e1af-4002-89e2-0de91f987538.gif)


#### Tools to Design or Visualize Architecture of Neural Network
https://github.com/ashishpatel26/Tools-to-Design-or-Visualize-Architecture-of-Neural-Network

# Tensorflow

![model](https://user-images.githubusercontent.com/110838853/226787695-e9a735a2-c3f0-4e71-bf69-a270b8f5efa1.png)

TensorFlow is an open-source software library for dataflow and differentiable programming across a range of tasks. It was developed by the Google Brain team and released in 2015.

TensorFlow is designed to enable efficient numerical computation using data flow graphs. In a data flow graph, nodes represent mathematical operations, while edges represent the data that flows between them. This allows complex mathematical computations to be expressed in a simple, intuitive way, making it easier to develop and train machine learning models.

TensorFlow provides a comprehensive ecosystem of tools and libraries for building and deploying machine learning models, including:

TensorFlow Core: The central component of the TensorFlow library, providing support for building and training machine learning models using data flow graphs.

Keras: A high-level neural networks API that makes it easy to build and train deep learning models.

TensorFlow Extended (TFX): A platform for building end-to-end machine learning pipelines, from data ingestion to model serving.

TensorFlow.js: A JavaScript library for training and deploying machine learning models in the browser or on Node.js.

TensorFlow Lite: A lightweight version of TensorFlow designed for mobile and embedded devices.

Overall, TensorFlow has become a widely used tool in the machine learning community, enabling researchers and developers to build and deploy state-of-the-art machine learning models for a wide range of applications.


#### Learning Tensorflow Step by Step:: Concepts, Examples & Applications
https://github.com/suvoooo/Learn-TensorFlow


#### Introduction to Tensorflow 2 for Computer Vision by AIFEE -
https://learn.aifee.co/p/introduction-to-tensorflow-2-for-computer-vision?ck_subscriber_id=2076754537&utm_source=convertkit&utm_medium=email&utm_campaign=Welcome+to+AIFEE+Newsletter%21%20-%204653438

#### Tensorflow Models
https://github.com/tensorflow/models/tree/master/research  ##Models and examples built with TensorFlow

# Pytorch
![01_a_pytorch_workflow](https://user-images.githubusercontent.com/110838853/226788275-89bb2940-b100-42cd-a1a8-eba849aee218.png)

PyTorch is an open-source machine learning framework that was developed by Facebook AI Research (FAIR) and released in 2016. It is built on top of the Python programming language and is designed to provide a flexible and easy-to-use platform for building and training machine learning models.

PyTorch uses a dynamic computational graph, which means that the graph is generated on-the-fly during the execution of the program. This provides a high degree of flexibility and allows for efficient implementation of complex models, such as recurrent neural networks and generative adversarial networks.

PyTorch also provides a range of tools and libraries for building and training machine learning models, including:

TorchScript: A tool for serializing PyTorch models to a format that can be deployed to production environments.

TorchVision: A library of datasets and model architectures for computer vision tasks.

TorchText: A library for natural language processing tasks, such as text classification and language translation.

PyTorch Lightning: A lightweight wrapper for PyTorch that simplifies the process of building and training complex models.

Overall, PyTorch has become a popular tool in the machine learning community due to its flexibility, ease of use, and strong community support. It has been used to build state-of-the-art models in a variety of fields, including computer vision, natural language processing, and reinforcement learning.


#### A collection of PyTorch notebooks for learning and practicing deep learning
https://github.com/dair-ai/pytorch_notebooks

####  Notebooks 
https://github.com/dair-ai/Mathematics-for-ML


# Computer Vision and CNN

![89175cnn_banner](https://user-images.githubusercontent.com/110838853/226784233-75acbbcd-7162-4a02-a2da-6b113d293c5a.png)

Computer vision is a field of artificial intelligence that focuses on enabling machines to interpret and understand visual data from the world around us, such as images and videos. It involves developing algorithms and techniques that allow computers to analyze, process, and understand digital images and videos in a way that is similar to how humans perceive and interpret visual information.

Convolutional neural networks (CNNs) are a type of deep learning algorithm that are commonly used in computer vision tasks such as image recognition, object detection, and image segmentation. CNNs are inspired by the structure of the human visual system and are designed to automatically learn hierarchical representations of visual data.

CNNs are made up of multiple layers, including convolutional layers, pooling layers, and fully connected layers. The convolutional layers use filters to convolve over the input image, detecting features such as edges, textures, and shapes. The pooling layers then reduce the spatial size of the output feature maps, making the network more efficient and allowing it to focus on the most important features. The fully connected layers then take the output from the convolutional and pooling layers and use it to make a final classification or prediction.

CNNs have been shown to achieve state-of-the-art performance on a wide range of computer vision tasks and are widely used in industry and academia for image and video analysis.



#### Computer vision Use cases
https://github.com/ashishpatel26/Computer-Vision-Industry-Use-Cases ## useful for the interview preparation and knowledge of CNN


## CNN
https://copyassignment.com/flower-classification-using-cnn/
### **Must Read Github Repository for CNN**
https://github.com/Avik-Jain/DeepLearning.ai-Summary/tree/master/4-%20Convolutional%20Neural%20Networks 

### CNN Course 

https://madewithml.com/courses/foundations/convolutional-neural-networks/

# YOLO

![ezgif-3-fba2e64257](https://user-images.githubusercontent.com/110838853/226788844-c8ea00fd-85f3-4a4a-8fe5-7b47c078a27a.jpg)

YOLO (You Only Look Once) is an object detection algorithm used in computer vision. It was first introduced in a paper by Joseph Redmon et al. in 2016. YOLO is designed to be fast and efficient, capable of processing images in real-time on a standard desktop GPU.

The YOLO algorithm works by dividing an input image into a grid of cells, and for each cell, predicting a set of bounding boxes and associated class probabilities. Each bounding box consists of four coordinates (x, y, width, height), which define the location and size of an object within the image. The class probabilities indicate the likelihood that the object within the bounding box belongs to a particular class, such as person, car, or bicycle.

One of the main advantages of YOLO is its speed and efficiency. By processing the entire image at once, YOLO is able to detect objects in real-time, making it useful for applications such as self-driving cars and real-time surveillance. Additionally, YOLO is able to detect small objects and objects with low contrast, which can be challenging for other object detection algorithms.

Since its initial release, several variants of YOLO have been developed, including YOLOv2, YOLOv3, and YOLOv4. These variants incorporate improvements such as feature extraction from multiple scales, better regularization techniques, and use of novel architectures such as the spatial pyramid pooling module.

Overall, YOLO has become a popular algorithm in the computer vision community due to its speed and accuracy, and has been used in a wide range of applications, including autonomous vehicles, security systems, and robotics.


#### YOLOv4 / Scaled-YOLOv4 / YOLO - Neural Networks for Object Detection (Windows and Linux version of Darknet )
https://github.com/AlexeyAB/darknet

#### YOLOv5 🚀 in PyTorch 
https://github.com/ultralytics/yolov5


### Resources for CNN,ML,NLP
https://github.com/ashishpatel26/ResourceBank_CV_NLP_MLOPS_2022   ###This repository offers a goldmine of materials for  computer vision, natural language processing, and machine learning operations.

####  Notebooks 
https://github.com/dair-ai/Mathematics-for-ML

### Explanation to key concepts in CNN
https://github.com/dair-ai/ML-Papers-Explained


#  Object Detection

![Detected-with-YOLO--Schreibtisch-mit-Objekten](https://user-images.githubusercontent.com/110838853/226789288-7c81f8c1-b0a0-4a93-96a4-3f2ed8e3911e.jpg)

Object detection is a computer vision technique used to locate and identify objects within an image or video. It involves identifying the presence of objects in an image or video and their corresponding class labels, as well as the precise location of each object within the image or video.

Object detection can be divided into two main stages:

Object Localization: The first stage involves finding the location of objects within the image or video. This is typically done by predicting a set of bounding boxes that enclose each object of interest. Each bounding box consists of four coordinates (x, y, width, height) that define the location and size of the object.

Object Classification: The second stage involves identifying the class label of each object within the bounding box. This is typically done by using a machine learning algorithm that has been trained on a dataset of labeled images or videos.

Object detection has many applications, including self-driving cars, surveillance systems, and robotics. It can also be used for tasks such as counting the number of people in a crowd or detecting anomalies in medical images. Object detection algorithms typically involve complex machine learning models, such as convolutional neural networks (CNNs), and are computationally intensive. However, recent advancements in hardware and software have made it possible to perform object detection in real-time on standard computing devices.


#### Collection of papers and other resources for object tracking and detection using deep learning
https://github.com/ashishpatel26/Deep-Learning-for-Tracking-and-Detection 



# Large Language Model(LLM)
Large language models are a type of machine learning model used in natural language processing that are capable of generating human-like text by predicting the probability distribution of words in a given sequence. These models are trained on massive datasets of text, typically using unsupervised learning techniques, and are capable of generating text that is difficult to distinguish from text written by humans.

Large language models can be divided into two main types: autoregressive models and transformer models.

Autoregressive models, such as the GPT series from OpenAI, generate text one word at a time, conditioned on the previous words in the sequence. These models typically use recurrent neural networks (RNNs) or transformers to model the conditional probability distribution of each word given the previous words in the sequence.

Transformer models, such as BERT from Google and T5 from Google Brain, are based on the transformer architecture, which was introduced in a paper by Vaswani et al. in 2017. Transformers use a self-attention mechanism to allow each token in the sequence to attend to all other tokens, enabling the model to capture long-range dependencies in the text.

Large language models have a wide range of applications, including language translation, chatbots, content generation, and sentiment analysis. However, they have also raised concerns about their potential to be used for misinformation, propaganda, and other malicious purposes.





#### CheatSheet-LLM
https://github.com/Abonia1/CheatSheet-LLM





# other Resources To Help with Projects and Understanding Key Concepts

### 500 Projects of Deep learning and CNN and NLP 
https://github.com/ashishpatel26/500-AI-Machine-learning-Deep-learning-Computer-vision-NLP-Projects-with-code ##500 AI Machine learning Deep learning Computer vision NLP Projects with code

### All algorithms implementd on Python
https://github.com/TheAlgorithms/Python


# Chatgpt-prompts

![download (4)](https://user-images.githubusercontent.com/110838853/226790067-ee246d94-d5ab-4736-83a3-5ccaab274096.png)

#### Awesome Chatgpt-prompts for different Scenarios   
https://github.com/f/awesome-chatgpt-prompts   ##This repo includes ChatGPT prompt curation to use ChatGPT better.





# NLP

![pnlp_0101](https://user-images.githubusercontent.com/110838853/226782983-768b069e-52ed-4442-8909-d9553ab8b61a.png)

NLP stands for natural language processing, which is a branch of artificial intelligence that focuses on the interaction between computers and human language. It involves the development of algorithms and models that enable computers to understand, interpret, and generate human language.

NLP has many applications, including:

Text classification: The process of categorizing text into one or more predefined categories, such as sentiment analysis (determining whether a piece of text expresses a positive or negative sentiment) or topic classification (categorizing text into topics such as politics, sports, or entertainment).

Machine translation: The process of automatically translating text from one language to another.

Named entity recognition: The process of identifying and extracting entities such as people, places, and organizations from text.

Sentiment analysis: The process of determining the sentiment expressed in a piece of text, whether it is positive, negative, or neutral.

Question answering: The process of answering natural language questions posed by humans.

NLP involves a range of techniques, including statistical models, rule-based models, and deep learning models such as recurrent neural networks (RNNs) and transformers. These models are trained on large datasets of annotated text to learn the patterns and structures of language, and are used to perform a wide range of tasks in natural language processing.


#### NLP Course Notes and Videos
https://github.com/ashishpatel26/ML-Course-Notes

### Resources for CNN,ML,NLP
https://github.com/ashishpatel26/ResourceBank_CV_NLP_MLOPS_2022   ###This repository offers a goldmine of materials for  computer vision, natural language processing, and machine learning operations.


### Curated List of Papers on NLP
https://github.com/dair-ai/nlp_paper_summaries

####  Notebooks 
https://github.com/dair-ai/Mathematics-for-ML



# Transformers

![Transformer-apps](https://user-images.githubusercontent.com/110838853/226783432-63a3ebfc-2789-47f9-bc1f-4dbb11f30a1e.jpg)

Transformers are a type of machine learning architecture used primarily for natural language processing tasks such as language translation, sentiment analysis, and text classification. The Transformer architecture was first introduced in a 2017 paper called "Attention is All You Need" by Vaswani et al.

Traditionally, recurrent neural networks (RNNs) have been used for sequence-to-sequence tasks, but Transformers have gained popularity due to their ability to handle long-range dependencies in sequences more efficiently.

Transformers rely on self-attention mechanisms to determine which parts of a sequence are most relevant to each other. Self-attention allows the model to weigh the importance of different words or tokens in a sequence when generating an output.

Transformers have been used with great success in various natural language processing tasks and have even been applied to other domains such as image and audio processing. The pre-trained transformer models such as BERT, GPT-3, and T5 have achieved state-of-the-art results on a wide range of natural language processing benchmarks.


#### Study Guide to learn Transformers
https://github.com/dair-ai/Transformers-Recipe

#### Resources for Transformers
https://github.com/ashishpatel26/Treasure-of-Transformers ## Awesome Treasure of Transformers Models for Natural Language processing contains papers, videos, blogs, official repo along with colab Notebooks.

#### Transformers Course Notes and Videos
https://github.com/ashishpatel26/ML-Course-Notes

### Explanation to key concepts in Tranformers papers
https://github.com/dair-ai/ML-Papers-Explained

#### Medium Article for The Resources of Transformers
https://medium.com/nlplanet/two-minutes-nlp-20-learning-resources-for-transformers-1bbff88b7524 ##20 Learning Resources for Transformers


####  Notebooks 
https://github.com/dair-ai/Mathematics-for-ML

# Portfolio
![GitHub](https://user-images.githubusercontent.com/110838853/226789623-a1c16114-2058-483c-b08b-45ea611979d3.jpeg)


#### A curated list of awesome GitHub Profile READMEs
https://github.com/abhisheknaiidu/awesome-github-profile-readme

#### How to make an impressive Data Science Portfolio?
https://www.analyticsvidhya.com/blog/2021/04/how-to-make-an-impressive-data-science-portfolio/


# GAN

![BP3_fig1-1024x390](https://user-images.githubusercontent.com/110838853/226784902-30e81abf-06d9-444f-adf2-096eeb8c3e4f.jpg)

GAN stands for Generative Adversarial Networks, which is a type of deep learning model used in unsupervised machine learning tasks such as image generation, video generation, and text generation. GANs were first introduced by Ian Goodfellow in 2014.

A GAN consists of two neural networks: a generator and a discriminator. The generator takes random noise as input and produces an output, such as an image or a piece of text. The discriminator takes as input the output from the generator, as well as real samples from the training data, and tries to distinguish between the real and fake samples.

During training, the generator and discriminator are trained in a adversarial way. The generator tries to produce outputs that fool the discriminator into thinking they are real, while the discriminator tries to accurately distinguish between the real and fake samples. This process continues until the generator is able to produce samples that are indistinguishable from the real samples, and the discriminator is no longer able to distinguish between the real and fake samples.

GANs have been used for a wide range of applications, such as image synthesis, image editing, and data augmentation. They have shown remarkable performance in generating realistic images, and have been used to create images of faces, animals, and even furniture. GANs have also been used for other types of generative tasks, such as generating music, video, and speech.




####  Notebooks 
https://github.com/dair-ai/Mathematics-for-ML

# Graph Neural Networks (GNNs)

![GNN-03-scaled](https://user-images.githubusercontent.com/110838853/226785402-cec303e4-f1e2-414d-b2d6-41e1e086f749.jpg)

GNN stands for Graph Neural Network, which is a type of machine learning model designed to operate on graphs and other network data structures.

In a graph, nodes are connected by edges that represent relationships or connections between them. GNNs are designed to learn from and operate on these graph structures, allowing them to model complex relationships and dependencies between nodes.

GNNs work by propagating information through the graph structure, updating each node's representation based on its neighboring nodes and edges. This propagation process is typically performed through a series of message-passing steps that update node features based on the features of neighboring nodes and edges.

GNNs have been used in a variety of applications, such as social network analysis, recommendation systems, and drug discovery. They have been shown to be particularly effective in tasks where the relationships between data points are crucial for accurate predictions, such as in protein structure prediction and traffic prediction.

Some popular GNN architectures include Graph Convolutional Networks (GCNs), Graph Attention Networks (GATs), and GraphSAGE.

#### A study guide to learn about Graph Neural Networks (GNNs)
https://github.com/dair-ai/GNNs-Recipe  

# Linux

![s2-1](https://user-images.githubusercontent.com/110838853/226791459-fd4a02e2-b12d-4bcf-b53b-57e59dfea9b4.jpg)

Linux is a free and open-source operating system that is widely used in the computer industry. It was first created by Linus Torvalds in 1991 as a variant of the Unix operating system and has since become a popular choice for servers, desktop computers, and other computing devices.

One of the main advantages of Linux is its open-source nature, which allows users to access and modify the source code of the operating system. This has led to the development of a large and active community of developers who contribute to the development and improvement of Linux. As a result, Linux has become a highly customizable and flexible operating system, with a wide range of distributions (or "distros") available to suit different needs and preferences.

Linux is also known for its stability, security, and reliability. It is less vulnerable to malware and other security threats than other operating systems, and its modular architecture allows for easy customization and configuration.

Linux is used in a wide range of applications, including web servers, cloud computing, scientific research, and embedded systems. Many popular software applications, including the Apache web server, MySQL database, and the Python programming language, are also available for use on Linux.

# Data Analysis and Analytics
Data analysis is the process of inspecting, cleaning, transforming, and modeling data in order to extract useful information and insights from it. The goal of data analysis is to uncover patterns, relationships, and trends in the data, and to use this information to make informed decisions.

Data analysis can be divided into several stages:

Data collection: The process of gathering data from various sources, such as databases, spreadsheets, surveys, or sensors.

Data cleaning: The process of identifying and correcting errors or inconsistencies in the data, such as missing values, outliers, or incorrect data types.

Data transformation: The process of converting the data into a suitable format for analysis, such as aggregating, filtering, or scaling the data.

Data modeling: The process of creating statistical models or machine learning models to identify patterns and relationships in the data, and to make predictions or classifications based on this information.

Data visualization: The process of creating visual representations of the data, such as charts, graphs, or maps, to help users understand and interpret the results of the analysis.

Data analysis is used in a wide range of applications, including business intelligence, scientific research, social sciences, healthcare, and finance. It can help organizations make more informed decisions, identify new opportunities, and optimize their operations.

#### Difference Between Data analysis and Data analytics
Data analysis and analytics are both related to the process of extracting insights from data, but there are some differences between the two:

Scope: Data analysis is a broad term that refers to the process of examining and interpreting data to draw conclusions or make decisions. Data analytics is a more specialized subset of data analysis that focuses specifically on the use of statistical and quantitative methods to analyze data.

Purpose: Data analysis can be used for a variety of purposes, such as understanding trends, identifying outliers, or summarizing data. Data analytics is typically used for more advanced purposes, such as predicting outcomes or optimizing processes.

Techniques: Data analysis often involves using basic statistical techniques such as mean, median, and mode, while data analytics uses more advanced techniques such as regression analysis, machine learning algorithms, and optimization techniques.

Tools: Data analysis can be done using basic tools such as Excel or SQL, while data analytics typically requires more specialized tools such as Python, R, or SAS.

Overall, data analysis can be seen as a more general term that includes a wide range of techniques and approaches, while data analytics is a more specialized subset of data analysis that focuses specifically on the use of statistical and quantitative methods.


# SQL

![Sql_data_base_with_logo](https://user-images.githubusercontent.com/110838853/226792362-025b53c5-f0d3-440a-aa28-4e57e2d98c1c.png)

SQL (Structured Query Language) is a programming language used for managing and manipulating data stored in relational databases. It is a standard language used by database management systems (DBMS) such as MySQL, Oracle, Microsoft SQL Server, PostgreSQL, and SQLite.

SQL allows users to perform a variety of tasks such as creating and modifying tables, inserting and updating data, selecting and filtering data, and joining multiple tables.

SQL is used by data analysts, database administrators, software developers, and other professionals who work with databases. It is an important skill for anyone working with data, as it provides a powerful tool for managing and querying large datasets.

#### SQL Data Analysis & Data Visualizaiton Projects
https://github.com/ptyadana/SQL-Data-Analysis-and-Visualization-Projects ##SQL data analysis & visualization projects using MySQL, PostgreSQL, SQLite, Tableau, Apache Spark and pySpark.

# Tableau

![Tableau-Logo-for-website (1)](https://user-images.githubusercontent.com/110838853/226799442-c03a1e49-d402-4e26-ae65-b3bde4fac785.jpg)

Tableau is a data visualization and business intelligence software that helps people see and understand their data. It provides a suite of tools for creating interactive dashboards, reports, and visualizations, allowing users to explore data and uncover insights in real-time.

With Tableau, users can connect to a variety of data sources including spreadsheets, databases, and cloud services. They can then drag and drop fields onto a canvas to create charts, graphs, and other visualizations. Tableau's visualization capabilities are highly customizable, with options for color palettes, formatting, and interactivity.

Tableau also offers a range of advanced analytics features, such as statistical modeling and forecasting, spatial analysis, and data blending. It supports collaboration and sharing through its cloud-based platform, allowing users to share their analyses and visualizations with others in their organization.

### MySQL-Tableau-for-Data-Analytics-and-Business-Intelligence
https://github.com/ptyadana/MySQL-Tableau-for-Data-Analytics-and-Business-Intelligence

# Flask
![1_0G5zu7CnXdMT9pGbYUTQLQ](https://user-images.githubusercontent.com/110838853/226799579-3b039bc4-4749-456f-ab8e-320de3aff665.png)


Flask is a web application framework for Python that allows developers to build web applications quickly and easily. It is a lightweight and flexible framework that provides a simple yet powerful way to create web applications.

Flask provides a range of features and tools that make it easy to build web applications, including a built-in development server, support for URL routing, and a templating engine for creating HTML pages. It also supports extensions, which provide additional functionality for tasks such as form handling, authentication, and database integration.

One of the key features of Flask is its flexibility. It allows developers to choose the components they need and leave out the ones they don't. This makes it possible to build applications that are lightweight, fast, and tailored to specific needs.

Flask is often used for building small to medium-sized web applications, such as blogs, e-commerce sites, and data visualizations. It is widely used in the Python community and has a large ecosystem of extensions and plugins available.


# Machine learning and Deep learning Model deployment using API Resources

#### iris flower predictions Machine Learning app using Tensorflow, Keras, ScikitLearn, Flask deployed on Heroku
https://github.com/ptyadana/iris-flower-ML-app

#### Awesome-Machine-learning-Deep-learning-Deployment
https://github.com/ashishpatel26/Awesome-Machine-learning-Deep-learning-Deployment

# End to End Machine learning Projects Deployement
![end-to-end-ml-0](https://user-images.githubusercontent.com/110838853/226795923-ef3bd5e1-2055-4e00-a42c-6f22fe3f5263.png)

#### 1.GitHub Repo
https://github.com/pratik-276/End-to-End-Machine-Learning-Projects
