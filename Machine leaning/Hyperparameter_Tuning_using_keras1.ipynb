{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "For any doubt in  this code and in Hyperparameter Tuning with keras go to [Keras.tuner](https://keras.io/keras_tuner/) Website"
      ],
      "metadata": {
        "id": "7i2Iw75KoE2G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XHrFzYziNkpX"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "(x, y), (x_test, y_test) = keras.datasets.mnist.load_data()\n",
        "\n",
        "x_train = x[:-10000]\n",
        "x_val = x[-10000:]\n",
        "y_train = y[:-10000]\n",
        "y_val = y[-10000:]\n",
        "\n",
        "x_train = np.expand_dims(x_train, -1).astype(\"float32\") / 255.0\n",
        "x_val = np.expand_dims(x_val, -1).astype(\"float32\") / 255.0\n",
        "x_test = np.expand_dims(x_test, -1).astype(\"float32\") / 255.0\n",
        "\n",
        "num_classes = 10\n",
        "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
        "y_val = keras.utils.to_categorical(y_val, num_classes)\n",
        "y_test = keras.utils.to_categorical(y_test, num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install keras-tuner -q\n"
      ],
      "metadata": {
        "id": "OPMlBmx1OZwk"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n"
      ],
      "metadata": {
        "id": "o81UK8urOaiu"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import keras_tuner\n",
        "#build_model(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "id": "QfoJ9SNIOalh"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "urq8qb03jUkA"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This is the Code for Hyperparameters \n",
        "#Int method\n",
        "HyperParameters.Int(\n",
        "    name,\n",
        "    min_value,\n",
        "    max_value,\n",
        "    step=None,\n",
        "    sampling=\"linear\",\n",
        "    default=None,\n",
        "    parent_name=None,\n",
        "    parent_values=None,\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "collapsed": true,
        "id": "ClKvdndkOan5",
        "outputId": "22fb9bd4-495b-4912-8cab-2ae1b82d2399"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-4eae3369bf27>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#This is the Code for Hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#Int method\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m HyperParameters.Int(\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmin_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'HyperParameters' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Arguments\n",
        "\n",
        "- name: A string. the name of parameter. Must be unique for each HyperParameter instance in the search space.\n",
        "- min_value: Float, the lower bound of the range.\n",
        "- max_value: Float, the upper bound of the range.\n",
        "- step: Optional float, the distance between two consecutive samples in the range. If left unspecified, it is possible to sample any value in the interval. If sampling=\"linear\", it will be the minimum additve between two samples. If sampling=\"log\", it will be the minimum multiplier between two samples.\n",
        "- sampling: String. One of \"linear\", \"log\", \"reverse_log\". Defaults to \"linear\". When sampling value, it always start from a value in range [0.0, 1.0). The sampling argument decides how the value is projected into the range of [min_value, max_value]. \"linear\": min_value + value * (max_value - min_value) \"log\": min_value * (max_value / min_value) ^ value \"reverse_log\": (max_value - min_value * ((max_value / min_value) ^ (1 - value) - 1))\n",
        "default: Float, the default value to return for the parameter. If unspecified, the default value will be min_value.\n",
        "- parent_name: Optional string, specifying the name of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
        "- parent_values: Optional list of the values of the parent HyperParameter to use as the condition to activate the current HyperParameter.\n",
        "\n",
        "Returns:The value of the hyperparameter, or None if the hyperparameter is not active."
      ],
      "metadata": {
        "id": "Iuk2AXn4jbGA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_model(hp):\n",
        "    model = keras.Sequential()\n",
        "    model.add(layers.Flatten())\n",
        "    # Tune the number of layers.\n",
        "    for i in range(hp.Int(\"num_layers\", 1, 3)): # For this refer above code of Int Method for Hyperparameter Tuning\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                # Tune number of units separately.\n",
        "                units=hp.Int(f\"units_{i}\", min_value=32, max_value=512, step=32),\n",
        "                activation=hp.Choice(\"activation\", [\"relu\", \"tanh\"]),\n",
        "            )\n",
        "        )\n",
        "    if hp.Boolean(\"dropout\"):\n",
        "        model.add(layers.Dropout(rate=0.25))\n",
        "    model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "    learning_rate = hp.Float(\"lr\", min_value=1e-4, max_value=1e-2, sampling=\"log\") # for Hyperparameter Documentation https://keras.io/api/keras_tuner/hyperparameters/#hyperparameters\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=learning_rate),\n",
        "        loss=\"categorical_crossentropy\",\n",
        "        metrics=[\"accuracy\"],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "#To test if the model builds successfully.\n",
        "build_model(keras_tuner.HyperParameters())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQ2TsGQeOSEA",
        "outputId": "c849c5dd-aead-4f6e-c8a7-a364bfdc8f13"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.engine.sequential.Sequential at 0x7f3b3881e9e0>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pA3m03r_lGa2"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "[Keras.tuner.Randomsearch()](https://keras.io/api/keras_tuner/tuners/random/)\n",
        "\n",
        "for all kind of Tuner Class[Visis Here](https://keras.io/api/keras_tuner/tuners/)\n",
        "\n",
        "for Hyperparameter Documentaion  [visit Here](https://keras.io/api/keras_tuner/hyperparameters/#hyperparameters)\n",
        "\n",
        "### [More Objective We can try ](https://keras.io/api/metrics/)\n",
        "\n",
        "[keras_tuner.Objective(name, direction)]()\n",
        "\n",
        "The objective for optimization during tuning.\n",
        "\n",
        "###Arguments\n",
        "\n",
        "- name: String. The name of the objective.\n",
        "- direction: String. The value should be \"min\" or \"max\" indicating whether the objective value should be minimized or maximized.\n"
      ],
      "metadata": {
        "id": "vbQsVEzJlHUN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for this Function see Above Link\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_model,\n",
        "    objective=\"val_accuracy\", # for this function see above code of more objective we can try and objective funtion\n",
        "    max_trials=3,\n",
        "    executions_per_trial=2,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"helloworld\",\n",
        ")\n"
      ],
      "metadata": {
        "id": "sF9dGiUPOSPc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search_space_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ZktvTx7OSTJ",
        "outputId": "7cda633d-70f5-4df7-f67f-99c6f6a793a6"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Search space summary\n",
            "Default search space size: 5\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 1, 'max_value': 3, 'step': 1, 'sampling': 'linear'}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': 'linear'}\n",
            "activation (Choice)\n",
            "{'default': 'relu', 'conditions': [], 'values': ['relu', 'tanh'], 'ordered': False}\n",
            "dropout (Boolean)\n",
            "{'default': False, 'conditions': []}\n",
            "lr (Float)\n",
            "{'default': 0.0001, 'conditions': [], 'min_value': 0.0001, 'max_value': 0.01, 'step': None, 'sampling': 'log'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WGGQ6f63OSWL"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.search(x_train, y_train, epochs=2, validation_data=(x_val, y_val))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ROURcysHN3Lv",
        "outputId": "ddee1cf6-e55e-4545-c233-7f4dd3ae95cc"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 35s]\n",
            "val_accuracy: 0.9570500254631042\n",
            "\n",
            "Best val_accuracy So Far: 0.9570500254631042\n",
            "Total elapsed time: 00h 02m 03s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, coming to the best part, we will use an awesome function that comes with this tuner, i.e. the ‘tuner_search.get_best_models()’ function, that will report you a summary of the best model to use for your image classification data!\n",
        "\n",
        "[model=tuner_search.get_best_models(num_models=1)[0]]()\n"
      ],
      "metadata": {
        "id": "lIPWiWu2vrmg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the top 2 models.\n",
        "models = tuner.get_best_models(num_models=2)\n",
        "best_model = models[0]\n",
        "# Build the model.\n",
        "# Needed for `Sequential` without specified `input_shape`.\n",
        "best_model.build(input_shape=(None, 28, 28))\n",
        "best_model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vhi97sAsOJLc",
        "outputId": "bab6529d-26be-42a1-abb3-e2632ea9b468"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 784)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 96)                75360     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                970       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 76,330\n",
            "Trainable params: 76,330\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tuner.results_summary()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w9j9jGVHPqsk",
        "outputId": "0644bc4b-6918-4061-b54f-f3cd71fa2679"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results summary\n",
            "Results in my_dir/helloworld\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_accuracy\", direction=\"max\")\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "num_layers: 1\n",
            "units_0: 96\n",
            "activation: relu\n",
            "dropout: False\n",
            "lr: 0.009021311428169284\n",
            "units_1: 96\n",
            "units_2: 320\n",
            "Score: 0.9570500254631042\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "num_layers: 3\n",
            "units_0: 288\n",
            "activation: tanh\n",
            "dropout: True\n",
            "lr: 0.00022419548935667316\n",
            "units_1: 160\n",
            "units_2: 32\n",
            "Score: 0.9537000060081482\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "num_layers: 2\n",
            "units_0: 448\n",
            "activation: tanh\n",
            "dropout: False\n",
            "lr: 0.0038025483399172595\n",
            "units_1: 32\n",
            "Score: 0.9451499879360199\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model.fit(x_train,y_train, epochs=10, validation_split=0.1, initial_epoch=3)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m90bEV5PwDzb",
        "outputId": "d4384003-2c78-4f12-b69c-1f10fd7bb970"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-0.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.kernel\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).layer_with_weights-1.bias\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Detecting that an object or model or tf.train.Checkpoint is being deleted with unrestored values. See the following logs for the specific values in question. To silence these warnings, use `status.expect_partial()`. See https://www.tensorflow.org/api_docs/python/tf/train/Checkpoint#restorefor details about the status object returned by the restore function.\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.1\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.2\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.3\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.4\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.5\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.6\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.7\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.8\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.9\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.10\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.11\n",
            "WARNING:tensorflow:Value in checkpoint could not be found in the restored object: (root).optimizer._variables.12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/10\n",
            "1407/1407 [==============================] - 6s 3ms/step - loss: 0.1297 - accuracy: 0.9628 - val_loss: 0.1316 - val_accuracy: 0.9620\n",
            "Epoch 5/10\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1217 - accuracy: 0.9667 - val_loss: 0.1975 - val_accuracy: 0.9554\n",
            "Epoch 6/10\n",
            "1407/1407 [==============================] - 5s 4ms/step - loss: 0.1051 - accuracy: 0.9713 - val_loss: 0.2405 - val_accuracy: 0.9502\n",
            "Epoch 7/10\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.1091 - accuracy: 0.9712 - val_loss: 0.1745 - val_accuracy: 0.9610\n",
            "Epoch 8/10\n",
            "1407/1407 [==============================] - 5s 3ms/step - loss: 0.1003 - accuracy: 0.9743 - val_loss: 0.2190 - val_accuracy: 0.9578\n",
            "Epoch 9/10\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0857 - accuracy: 0.9773 - val_loss: 0.2240 - val_accuracy: 0.9592\n",
            "Epoch 10/10\n",
            "1407/1407 [==============================] - 4s 3ms/step - loss: 0.0947 - accuracy: 0.9762 - val_loss: 0.2219 - val_accuracy: 0.9574\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b393b0280>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lHGYH9S7xItt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "y9fOAWWaxJhx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Voh15ab4xJkb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "T3kcXH5SxJnC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Retrain the model\n",
        "If you want to train the model with the entire dataset, you may retrieve the best hyperparameters and retrain the model by yourself.\n"
      ],
      "metadata": {
        "id": "HOtFvB-BQDAA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Get the top 2 hyperparameters.\n",
        "best_hps = tuner.get_best_hyperparameters(5)\n",
        "# Build the model with the best hp.\n",
        "model = build_model(best_hps[0])\n",
        "# Fit with the entire dataset.\n",
        "x_all = np.concatenate((x_train, x_val))\n",
        "y_all = np.concatenate((y_train, y_val))\n",
        "model.fit(x=x_all, y=y_all, epochs=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "guuFPIlsP2e9",
        "outputId": "00199353-1d40-45e0-aacb-1c1fffd20295"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2398 - accuracy: 0.9283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b39359000>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SQD6kTHVQWNZ"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EvQgYwyrR9_c"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "HyperModel class is subclassed to define a model building and training process. The build() method of the HyperModel class is used to create a Keras model using the hyperparameters, and the fit() method is used to train the model and return the training history.\n",
        "\n",
        "In the fit() method, the shuffle argument in model.fit() is tuned. The shuffle argument controls whether the training data is shuffled before each epoch. Shuffling the training data can help to improve the model's generalization performance."
      ],
      "metadata": {
        "id": "N1U8VeqkUk8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "        model.compile(\n",
        "            optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, *args, **kwargs):\n",
        "        return model.fit(\n",
        "            *args,\n",
        "            # Tune whether to shuffle the data in each epoch.\n",
        "            shuffle=hp.Boolean(\"shuffle\"),\n",
        "            **kwargs,\n",
        "        )\n"
      ],
      "metadata": {
        "id": "VXgu-ie0R-CE"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Again, we can do a quick check to see if the code works correctly.\n",
        "\n",
        "hp = keras_tuner.HyperParameters()\n",
        "hypermodel = MyHyperModel()\n",
        "model = hypermodel.build(hp)\n",
        "hypermodel.fit(hp, model, np.random.rand(100, 28, 28), np.random.rand(100, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pTOkDMlXSAh9",
        "outputId": "1659abc9-0213-4b8a-f47a-e7a41c75e24d"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 5ms/step - loss: 13.1279 - accuracy: 0.1200\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b39365480>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Tune data preprocessing\n",
        "To tune data preprocessing, we just add an additional step in HyperModel.fit(), where we can access the dataset from the arguments. In the following code, we tune whether to normalize the data before training the model. This time we explicitly put x and y in the function signature because we need to use them."
      ],
      "metadata": {
        "id": "N_3dL3AaUxan"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MyHyperModel(keras_tuner.HyperModel):\n",
        "    def build(self, hp):\n",
        "        model = keras.Sequential()\n",
        "        model.add(layers.Flatten())\n",
        "        model.add(\n",
        "            layers.Dense(\n",
        "                units=hp.Int(\"units\", min_value=32, max_value=512, step=32),\n",
        "                activation=\"relu\",\n",
        "            )\n",
        "        )\n",
        "        model.add(layers.Dense(10, activation=\"softmax\"))\n",
        "        model.compile(\n",
        "            optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"],\n",
        "        )\n",
        "        return model\n",
        "\n",
        "    def fit(self, hp, model, x, y, **kwargs):\n",
        "        if hp.Boolean(\"normalize\"):\n",
        "            x = layers.Normalization()(x)\n",
        "        return model.fit(\n",
        "            x,\n",
        "            y,\n",
        "            # Tune whether to shuffle the data in each epoch.\n",
        "            shuffle=hp.Boolean(\"shuffle\"),\n",
        "            **kwargs,\n",
        "        )\n",
        "\n",
        "\n",
        "hp = keras_tuner.HyperParameters()\n",
        "hypermodel = MyHyperModel()\n",
        "model = hypermodel.build(hp)\n",
        "hypermodel.fit(hp, model, np.random.rand(100, 28, 28), np.random.rand(100, 10))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dMpMFyK0UGMf",
        "outputId": "a7bd3afe-18af-4dc9-cf68-821bdfebfa28"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 5ms/step - loss: 14.6753 - accuracy: 0.0600\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f3b3976a500>"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def build_regressor(hp):\n",
        "    model = keras.Sequential(\n",
        "        [\n",
        "            layers.Dense(units=hp.Int(\"units\", 32, 128, 32), activation=\"relu\"),\n",
        "            layers.Dense(units=1),\n",
        "        ]\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=\"adam\",\n",
        "        loss=\"mean_squared_error\",\n",
        "        # Objective is one of the metrics.\n",
        "        metrics=[keras.metrics.MeanAbsoluteError()],\n",
        "    )\n",
        "    return model\n",
        "\n",
        "\n",
        "tuner = keras_tuner.RandomSearch(\n",
        "    hypermodel=build_regressor,\n",
        "    # The objective name and direction.\n",
        "    # Name is the f\"val_{snake_case_metric_class_name}\".\n",
        "    objective=keras_tuner.Objective(\"val_mean_absolute_error\", direction=\"min\"),\n",
        "    max_trials=3,\n",
        "    overwrite=True,\n",
        "    directory=\"my_dir\",\n",
        "    project_name=\"built_in_metrics\",\n",
        ")\n",
        "\n",
        "tuner.search(\n",
        "    x=np.random.rand(100, 10),\n",
        "    y=np.random.rand(100, 1),\n",
        "    validation_data=(np.random.rand(20, 10), np.random.rand(20, 1)),\n",
        ")\n",
        "\n",
        "tuner.results_summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT4UGTp_VGCD",
        "outputId": "dd42a963-d405-4329-e597-7439ec79720f"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 02s]\n",
            "val_mean_absolute_error: 0.2734336853027344\n",
            "\n",
            "Best val_mean_absolute_error So Far: 0.2341572344303131\n",
            "Total elapsed time: 00h 00m 05s\n",
            "Results summary\n",
            "Results in my_dir/built_in_metrics\n",
            "Showing 10 best trials\n",
            "Objective(name=\"val_mean_absolute_error\", direction=\"min\")\n",
            "\n",
            "Trial 1 summary\n",
            "Hyperparameters:\n",
            "units: 32\n",
            "Score: 0.2341572344303131\n",
            "\n",
            "Trial 2 summary\n",
            "Hyperparameters:\n",
            "units: 64\n",
            "Score: 0.2734336853027344\n",
            "\n",
            "Trial 0 summary\n",
            "Hyperparameters:\n",
            "units: 96\n",
            "Score: 0.356167197227478\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xhBir5g3VgJ5"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Keep Keras code separate\n",
        "You can keep all your Keras code unchanged and use KerasTuner to tune it. It is useful if you cannot modify the Keras code for some reason.\n",
        "\n",
        "It also gives you more flexibility. You don't have to separate the model building and training code apart. However, this workflow would not help you save the model or connect with the TensorBoard plugins.\n",
        "\n",
        "To save the model, you can use trial.trial_id, which is a string to uniquely identify a trial, to construct different paths to save the models from different trials."
      ],
      "metadata": {
        "id": "42TuLYBUZVE1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "\n",
        "def keras_code(units, optimizer, saving_path):\n",
        "    # Build model\n",
        "    model = keras.Sequential(\n",
        "        [layers.Dense(units=units, activation=\"relu\"), layers.Dense(units=1),]\n",
        "    )\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"mean_squared_error\",\n",
        "    )\n",
        "\n",
        "    # Prepare data\n",
        "    x_train = np.random.rand(100, 10)\n",
        "    y_train = np.random.rand(100, 1)\n",
        "    x_val = np.random.rand(20, 10)\n",
        "    y_val = np.random.rand(20, 1)\n",
        "\n",
        "    # Train & eval model\n",
        "    model.fit(x_train, y_train)\n",
        "\n",
        "    # Save model\n",
        "    model.save(saving_path)\n",
        "\n",
        "    # Return a single float as the objective value.\n",
        "    # You may also return a dictionary\n",
        "    # of {metric_name: metric_value}.\n",
        "    y_pred = model.predict(x_val)\n",
        "    return np.mean(np.abs(y_pred - y_val))\n",
        "\n",
        "\n",
        "class MyTuner(keras_tuner.RandomSearch):\n",
        "    def run_trial(self, trial, **kwargs):\n",
        "        hp = trial.hyperparameters\n",
        "        return keras_code(\n",
        "            units=hp.Int(\"units\", 32, 128, 32),\n",
        "            optimizer=hp.Choice(\"optimizer\", [\"adam\", \"adadelta\"]),\n",
        "            saving_path=os.path.join(\"/tmp\", trial.trial_id),\n",
        "        )\n",
        "\n",
        "\n",
        "tuner = MyTuner(\n",
        "    max_trials=3, overwrite=True, directory=\"my_dir\", project_name=\"keep_code_separate\",\n",
        ")\n",
        "tuner.search()\n",
        "# Retraining the model\n",
        "best_hp = tuner.get_best_hyperparameters()[0]\n",
        "keras_code(**best_hp.values, saving_path=\"/tmp/best_model\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kO5C8X0dZW4s",
        "outputId": "0bda389f-80d7-4cbb-d0aa-62137ee424ef"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Trial 3 Complete [00h 00m 02s]\n",
            "default_objective: 1.0694726379974262\n",
            "\n",
            "Best default_objective So Far: 0.4292792261175326\n",
            "Total elapsed time: 00h 00m 05s\n",
            "4/4 [==============================] - 1s 5ms/step - loss: 0.1492\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 39ms/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2695190293193414"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pOoDkyvfZZ_b"
      },
      "execution_count": 38,
      "outputs": []
    }
  ]
}