
# Stanford Course(Standford CS231n 2017 Summary)
https://github.com/mbadry1/CS231n-2017-Summary


# Deeplearning.ai Course 

https://github.com/mbadry1/DeepLearning.ai-Summary

https://github.com/mbadry1/DeepLearning.ai-Summary/tree/master/1-%20Neural%20Networks%20and%20Deep%20Learning

##  Trending-Deep-Learning
https://github.com/mbadry1/Trending-Deep-Learning
https://github.com/mbadry1/Top-Deep-Learning

## Data science process
https://resources.experfy.com/bigdata-cloud/the-data-science-process/

## How to build a regression-model
https://resources.experfy.com/bigdata-cloud/how-to-build-a-regression-model-in-python/

## How to build a model
https://resources.experfy.com/ai-ml/how-to-build-a-machine-learning-model/

https://copyassignment.com/8-steps-to-build-a-machine-learning-model/

## CNN
https://copyassignment.com/flower-classification-using-cnn/

## Neural network
One min to have a general idea about Neural Network, which is a technique that could achieve many different aims, facial recognition, predicting, music composition, etc.

NN contains virtual ‘neurons’ that are arranged in layers that are connected to each other. The neurons pass on the information and thereby perform calculations.

The connections between the neurons also have values associated with them, called weights.

Those weights tell us how much the information from one layer matters for the next layer. The values of neurons and the weights of the connections are essentially the free parameters of the network.

By training the network, we want to find those values of the parameters that minimize a certain function, called the ‘loss function’. It is an optimization problem, we use a method called backpropagation to solve it.

Backpropagation means if the NN gives us a result that is not good enough, we go back and change the weights of neurons and their connections. This is how the network can learn from failure.
![1645940317303](https://user-images.githubusercontent.com/110838853/224456961-62efe7a4-e1af-4002-89e2-0de91f987538.gif)
